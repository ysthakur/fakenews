{"cells":[{"cell_type":"markdown","metadata":{"id":"FnTLm04zkzFM"},"source":["# Setup"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":161,"status":"ok","timestamp":1625785213216,"user":{"displayName":"Yash Thakur","photoUrl":"","userId":"12694896413693995597"},"user_tz":240},"id":"e4KRoFt9rzQR"},"outputs":[],"source":["import pandas as pd\n","import nltk"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181,"status":"ok","timestamp":1625785214599,"user":{"displayName":"Yash Thakur","photoUrl":"","userId":"12694896413693995597"},"user_tz":240},"id":"dSwxCMZunCO4","outputId":"701eef7e-9e04-41ec-80f3-343cf71664ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["for pkg in ['stopwords', 'punkt', 'wordnet']:\n","  nltk.download(pkg)"]},{"cell_type":"markdown","metadata":{"id":"mJ9B-DVQksPq"},"source":["# Loading data"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":163,"status":"ok","timestamp":1625787190589,"user":{"displayName":"Yash Thakur","photoUrl":"","userId":"12694896413693995597"},"user_tz":240},"id":"A5JjA4pocyDC"},"outputs":[],"source":["import re\n","\n","# Split rows of train.csv into [text, label] if possible\n","def split_text_label(text):\n","  # The first group is the text, the second is the label at the end\n","  match = re.match(r'^(.*)\\s+?([^\\s]+)$', text)\n","  \n","  if not match: raise ValueError(f'format wrong arg={text}')\n","  \n","  text = match.group(1)\n","  label = match.group(2)\n","  \n","  if label == '1':\n","    label = 1.0\n","  elif label == '0':\n","    label = 0.0\n","  elif label == 'label':\n","    return None # There's a line \"content label\" in the data\n","  else:\n","    raise ValueError(f'label wrong label={label}, text={text}')\n","  \n","  return [label, text.strip()]\n","\n","def mapl(f, list):\n","  '''Map a list eagerly'''\n","  return [f(elem) for elem in list]\n","\n","def load_csv(file_name):\n","  # Data obtained from https://www.kaggle.com/c/fakenewskdd2020/data\n","  with open(f'/content/drive/MyDrive/fakenewskdd2020/{file_name}.csv', 'r') as csv:\n","    next(csv) # Skip the header with the column titles\n","    return list(csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8um1nfIZTEWt"},"outputs":[],"source":["train_raw = mapl(split_text_label, load_csv('train'))\n","train_raw = [res for res in train_raw if res]\n","\n","X_train_raw = mapl(lambda text_label: text_label[1], train_raw)\n","y_train = mapl(lambda text_label: text_label[0], train_raw)\n","X_test_raw = mapl(lambda line: re.sub(re.compile('^\\\\d+\\t'), '', line), load_csv('test'))\n","y_test = mapl(lambda line: float(re.sub(re.compile('^\\\\d+,|\\n'), '', line)), load_csv('sample_submission'))\n","\n","assert len(X_train_raw) == len(y_train)\n","assert len(X_test_raw) == len(y_test)"]},{"cell_type":"markdown","metadata":{"id":"f0ZAqfJHk4we"},"source":["# Processing text"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":148,"status":"ok","timestamp":1625787171090,"user":{"displayName":"Yash Thakur","photoUrl":"","userId":"12694896413693995597"},"user_tz":240},"id":"8A45FkxuSULS"},"outputs":[],"source":["en_stopwords = set(nltk.corpus.stopwords.words('english'))\n","stemmer = nltk.stem.WordNetLemmatizer()"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1625787397512,"user":{"displayName":"Yash Thakur","photoUrl":"","userId":"12694896413693995597"},"user_tz":240},"id":"2_61d8upRoh4"},"outputs":[],"source":["# Copied from Angad's LDA_Demo.ipynb\n","def preprocess_text(document):\n","  # Remove all the special characters\n","  document = re.sub(r'\\W', ' ', str(document))\n","\n","  # remove all single characters\n","  document = re.sub(r'\\s+\\w\\s+', ' ', document)\n","\n","  # Remove single characters from the start\n","  document = re.sub(r'^\\w\\s+', ' ', document)\n","\n","  # Substituting multiple spaces with single space\n","  document = re.sub(r'\\s+', ' ', document, flags=re.I)\n","\n","  # Converting to Lowercase\n","  document = document.lower()\n","\n","  # Lemmatization\n","  tokens = document.split()\n","  tokens = [stemmer.lemmatize(word) for word in tokens]\n","  tokens = [word for word in tokens if len(word) \u003e 3 and word not in en_stopwords]\n","\n","  return tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"15BmFK3b09lrittqdjy5zqBIOqzQr4she"},"id":"OvqAE846S2bj","outputId":"07c515e0-1b79-4196-9273-a8b4486e7f4c"},"outputs":[],"source":["X_train = mapl(preprocess_text, X_train_raw)\n","X_test = mapl(preprocess_text, X_test_raw)\n","X_train, X_test"]},{"cell_type":"markdown","metadata":{"id":"TbxZDwijZ4nE"},"source":["# Training model"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":226,"status":"error","timestamp":1625787399806,"user":{"displayName":"Yash Thakur","photoUrl":"","userId":"12694896413693995597"},"user_tz":240},"id":"PmJKqD6hW1mp","outputId":"05097b1b-0158-4d18-eb93-ea85370a3f6e"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-51-626b923cbefd\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model = tfkeras.Sequential([\n\u001b[0;32m----\u003e 5\u001b[0;31m   \u001b[0mtfkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m ])\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    186\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    187\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 188\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: \u003cclass 'tensorflow.python.keras.layers.convolutional.Conv1D'\u003e"]}],"source":["import tensorflow as tf\n","import tensorflow.keras as tfkeras\n","\n","model = tfkeras.Sequential([\n","  tfkeras.layers.Conv1D\n","])"]},{"cell_type":"markdown","metadata":{"id":"_7QNm3bVZ8HB"},"source":["# Testing model"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPq3vB88YxHaEGJe+DQxcIG","collapsed_sections":["FnTLm04zkzFM"],"mount_file_id":"1_75GavANC7xZ_tZNWujClqpI2YcYzewU","name":"fakenews.ipynb","provenance":[{"file_id":"https://github.com/ysthakur/fakenews/blob/main/fakenews.ipynb","timestamp":1625673719939}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}